name: Unit Tests
env:
  # increment this when downloads substantially change to avoid the internet
  DOWNLOAD_CACHE_VERSION: '8'
  CAPTURE_PROCESS_REPLAY: 1
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

on:
  push:
    branches:
      - master
      - no_comgr_tmp
  pull_request:
  workflow_dispatch:

jobs:
  tests:
    strategy:
      fail-fast: false
      matrix:
        backend: [amd] #, triton]

    name: Tests on (${{ matrix.backend }})
    runs-on: ubuntu-22.04
    timeout-minutes: 20

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2 # NOTE: this fetches the HEAD commit of the PR
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
      - name: Cache python packages
        uses: actions/cache@v4
        with:
          path: ${{ env.Python3_ROOT_DIR }}/lib/python3.12/site-packages
          key: ${{ matrix.backend }}-packages-${{ hashFiles('**/setup.py') }}
      - name: Cache downloads
        uses: actions/cache@v4
        with:
          path: ~/.cache/tinygrad/downloads/
          key: downloads-cache-${{ matrix.backend }}-${{ env.DOWNLOAD_CACHE_VERSION }}
      - name: Set env
        run: printf "${{ matrix.backend == 'llvm' && 'LLVM=1' || matrix.backend == 'clang' && 'CLANG=1' || matrix.backend == 'gpu' && 'GPU=1' || matrix.backend == 'PTX' && 'FORWARD_ONLY=1\nJIT=1\nOPT=2\nCUDA=1\nPTX=1\nMOCKGPU=1' || matrix.backend == 'triton' && 'FORWARD_ONLY=1\nJIT=1\nOPT=2\nNV=1\nMOCKGPU=1\nTRITON=1\nTRITON_PTXAS_PATH=/usr/bin/ptxas' || matrix.backend == 'amd' && 'AMD=1\nMOCKGPU=1\nFORWARD_ONLY=1' || matrix.backend == 'nv' && 'NV=1\nMOCKGPU=1\nFORWARD_ONLY=1' }}" >> $GITHUB_ENV
      - name: Install OpenCL
        if: matrix.backend == 'gpu'
        run: |
          echo 'Acquire::http::Pipeline-Depth "5";' | sudo tee -a /etc/apt/apt.conf.d/99parallel
          echo "deb [ allow-insecure=yes ] https://apt.repos.intel.com/oneapi all main" | sudo tee /etc/apt/sources.list.d/oneAPI.list
          sudo apt update || true
          sudo apt install --allow-unauthenticated -y --no-install-recommends opencl-headers \
            intel-oneapi-runtime-openmp=2023.2.1-16 intel-oneapi-runtime-compilers-common=2023.2.1-16 intel-oneapi-runtime-compilers=2023.2.1-16 \
            intel-oneapi-runtime-dpcpp-sycl-opencl-cpu=2023.2.1-16 intel-oneapi-runtime-tbb-common=2021.10.0-49541 \
            intel-oneapi-runtime-tbb=2021.10.0-49541 intel-oneapi-runtime-opencl=2023.2.1-16
      - name: Install packages (cuda)
        if: matrix.backend == 'ptx' || matrix.backend == 'triton' || matrix.backend == 'nv'
        run: |
          echo 'Acquire::http::Pipeline-Depth "5";' | sudo tee -a /etc/apt/apt.conf.d/99parallel
          sudo apt update -y || true
          sudo apt install -y --no-install-recommends git g++ cmake ninja-build llvm-15-dev zlib1g-dev libglew-dev \
            flex bison libfl-dev libboost-thread-dev libboost-filesystem-dev nvidia-cuda-toolkit-gcc libzstd-dev
      - name: Cache gpuocelot
        if: matrix.backend == 'ptx' || matrix.backend == 'triton' || matrix.backend == 'nv'
        id: cache-build
        uses: actions/cache@v4
        env:
          cache-name: cache-gpuocelot-build
        with:
          path: ${{ github.workspace }}/gpuocelot/ocelot
          key: ubuntu22.04-gpuocelot-4524e34adb7eaccc6f71262f2e21d7052bb17c2f-rebuild-9
      - name: Clone/compile gpuocelot
        if: (matrix.backend == 'ptx' || matrix.backend == 'triton' || matrix.backend == 'nv') && steps.cache-build.outputs.cache-hit != 'true'
        run: |
          git clone --recurse-submodules https://github.com/gpuocelot/gpuocelot.git ${{ github.workspace }}/gpuocelot
          cd ${{ github.workspace }}/gpuocelot/ocelot
          git checkout 4524e34adb7eaccc6f71262f2e21d7052bb17c2f
          mkdir build
          cd build
          cmake .. -Wno-dev -G Ninja -DOCELOT_BUILD_TOOLS=OFF -DCMAKE_BUILD_ALWAYS=0 -DBUILD_TESTS_CUDA=OFF
          ninja
      - name: Install gpuocelot
        if: matrix.backend == 'ptx' || matrix.backend == 'triton' || matrix.backend == 'nv'
        run: |
          cd ${{ github.workspace }}/gpuocelot/ocelot/build
          sudo cp libgpuocelot.so /usr/lib/libgpuocelot.so
      - name: Install packages (amd)
        if: matrix.backend == 'amd'
        run: |
          echo 'Acquire::http::Pipeline-Depth "5";' | sudo tee -a /etc/apt/apt.conf.d/99parallel
          wget https://repo.radeon.com/rocm/rocm.gpg.key -O - | gpg --dearmor | sudo tee /etc/apt/keyrings/rocm.gpg > /dev/null
          sudo tee /etc/apt/sources.list.d/rocm.list <<'EOF'
          deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/rocm/apt/6.1.2 jammy main
          EOF
          echo -e 'Package: *\nPin: release o=repo.radeon.com\nPin-Priority: 600' | sudo tee /etc/apt/preferences.d/rocm-pin-600
          sudo apt update || true
          sudo apt install --no-install-recommends --allow-unauthenticated -y rocm-device-libs  rocm-llvm hsa-rocr comgr hsa-rocr-dev liburing-dev libc6-dev
          curl -s https://api.github.com/repos/Qazalin/remu/releases/latest | \
          jq -r '.assets[] | select(.name == "libremu.so").browser_download_url' | \
          sudo xargs curl -L -o /usr/local/lib/libremu.so
          sudo tee --append /etc/ld.so.conf.d/rocm.conf <<'EOF'
            /opt/rocm/lib
            /opt/rocm/lib64
          EOF
          sudo ldconfig
      - name: Install dependencies
        run: pip install -e '.[testing${{matrix.backend=='ptx'&&',cuda'||matrix.backend=='triton'&&',triton'||''}}]' --extra-index-url https://download.pytorch.org/whl/cpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/
      - name: newer llvm
        if: matrix.backend == 'amd'
        run: |
          /opt/rocm/llvm/bin/clang --version
          # wget https://repo.radeon.com/amdgpu/6.2.1/ubuntu/pool/main/l/llvm-amdgpu/libllvm18.1-amdgpu_18.1.60201-2038383.22.04_amd64.deb
          # dpkg-deb --fsys-tarfile libllvm18.1-amdgpu_18.1.60201-2038383.22.04_amd64.deb | tar -xvf - -C /tmp ./opt/amdgpu/lib/x86_64-linux-gnu/llvm-18.1/lib/libLLVM.so.18.1
          # ldd /tmp/opt/amdgpu/lib/x86_64-linux-gnu/llvm-18.1/lib/libLLVM.so.18.1
          # wget https://repo.radeon.com/amdgpu/5.7.1/ubuntu/pool/main/l/llvm-amdgpu/libllvm16.0.50701-amdgpu_16.0.50701-1664922.20.04_amd64.deb
          # dpkg-deb --fsys-tarfile  libllvm16.0.50701-amdgpu_16.0.50701-1664922.20.04_amd64.deb | tar -xvf - -C /tmp ./opt/amdgpu/lib/x86_64-linux-gnu/llvm-16.0/lib/libLLVM-16.so          
          # ldd /tmp/opt/amdgpu/lib/x86_64-linux-gnu/llvm-16.0/lib/libLLVM-16.so
          # wget https://repo.radeon.com/amdgpu/6.0/ubuntu/pool/main/l/llvm-amdgpu/libllvm17.0.60000-amdgpu_17.0.60000-1697589.20.04_amd64.deb
          # dpkg-deb --fsys-tarfile  libllvm17.0.60000-amdgpu_17.0.60000-1697589.20.04_amd64.deb | tar -xvf - -C /tmp ./opt/amdgpu/lib/x86_64-linux-gnu/llvm-17.0/lib/libLLVM-17.so          
          # ldd /tmp/opt/amdgpu/lib/x86_64-linux-gnu/llvm-17.0/lib/libLLVM-17.so
          # CI ubuntu22.04 AMD clang version 17.0.0 roc-6.1.2
          wget https://repo.radeon.com/amdgpu/6.1.2/ubuntu/pool/main/l/llvm-amdgpu/libllvm17.0-amdgpu_17.0.60102-1781449.22.04_amd64.deb
          dpkg-deb --fsys-tarfile  libllvm17.0-amdgpu_17.0.60102-1781449.22.04_amd64.deb | tar -xvf - -C /tmp ./opt/amdgpu/lib/x86_64-linux-gnu/llvm-17.0/lib/libLLVM-17.so          
          ldd /tmp/opt/amdgpu/lib/x86_64-linux-gnu/llvm-17.0/lib/libLLVM-17.so          
          
      - name: Check Device.DEFAULT and print some source
        run: |
          PYTHONPATH=${{ github.workspace }} python3 -c "from tinygrad import Device; assert Device.DEFAULT in ['LLVM','CLANG','CUDA','GPU','AMD','NV'], Device.DEFAULT"
          DEBUG=5 PYTHONPATH=${{ github.workspace }} FORWARD_ONLY=1 python3 test/test_ops.py TestOps.test_add
      - name: Run pytest (not cuda or amd)
        if: matrix.backend!='ptx' && matrix.backend!='triton' && matrix.backend != 'amd' && matrix.backend != 'nv'
        run: python -m pytest -n=auto test/ --ignore=test/unit --durations=20
      - name: Run ONNX (only LLVM)
        if: matrix.backend == 'llvm'
        run: python -m pytest -n=auto test/external/external_test_onnx_backend.py --durations=20
      - name: Run pytest (cuda)
        if: matrix.backend=='ptx'||matrix.backend=='triton'||matrix.backend=='nv'
        run: python -m pytest -n=auto test/ -k 'not (half or test_efficientnet_safetensors)' --ignore=test/external --ignore=test/models --ignore=test/unit --ignore test/test_gc.py --durations=20
      # - name: Run pytest test_dtype A (amd)
      #   if: matrix.backend=='amd'
      #   run: |
      #     PYTHONPATH=${{ github.workspace }} python test/test_dtype.py 
      # - name: Run pytest test_dtype B (amd)
      #   if: matrix.backend=='amd'
      #   run: |
      #     python -m pytest -n=auto test/test_dtype.py 
      #     # test/test_dtype_alu.py test/test_linearizer.py   --durations=20     
      - name: Run pytest (amd)
        if: matrix.backend=='amd'
        run: python -m pytest -n=auto test/test_ops.py test/test_dtype.py test/test_dtype_alu.py test/test_linearizer.py test/test_randomness.py test/imported/test_indexing.py test/test_hcq.py test/external/external_test_am.py --durations=40
      - name: Run TRANSCENDENTAL math
        run: TRANSCENDENTAL=2 python -m pytest -n=auto test/test_ops.py::TestOps::test_sin test/test_ops.py::TestOps::test_cos test/test_ops.py::TestOps::test_tan test/test_ops.py::TestOps::test_exp test/test_ops.py::TestOps::test_log --durations=20
      # - name: Run process replay tests
      #   run: |
      #     export PR_TITLE=$(jq -r .pull_request.title "$GITHUB_EVENT_PATH")
      #     export COMMIT_MESSAGE=$(git show -s --format=%B ${{ github.event.pull_request.head.sha }})
      #     cp test/external/process_replay/process_replay.py ./process_replay.py && git fetch origin master && git -c advice.detachedHead=false checkout origin/master && PYTHONPATH=. python3 process_replay.py

  